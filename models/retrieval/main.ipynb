{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-jonathan",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CS492H 2021 Prof. M Sung\n",
    "# PA2 AutoEncoder\n",
    "# Jeonghyun Kim\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import easydict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import PointNet\n",
    "from dataset import Dataset\n",
    "\n",
    "# @Ref: https://github.com/chrdiller/pyTorchChamferDistance\n",
    "from chamfer_distance.chamfer_distance import ChamferDistance \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "args = easydict.EasyDict({\n",
    "    'n_points': 2048,\n",
    "    'latent': 512,\n",
    "    'train': True, \n",
    "    'batch_size': 32,\n",
    "    'epoch': 50,\n",
    "    'n_workers': 4,\n",
    "    'lr': 0.001,\n",
    "    'b1': 0.9,\n",
    "    'b2': 0.999,\n",
    "    'step_size': 20,\n",
    "    'gamma': 0.5,\n",
    "    'data': 'shapenetcorev2',\n",
    "    'model': '', #'outputs/model128_50.pth',\n",
    "    'out_dir': 'outputs'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = Dataset(dataset_name=args.data, num_points=args.n_points, split='train')\n",
    "TEST_DATASET = Dataset(dataset_name=args.data, num_points=args.n_points, split='test')\n",
    "EVAL_DATASET = Dataset(dataset_name=args.data, num_points=args.n_points, split='val')\n",
    "\n",
    "TRAIN_DATALOADER = torch.utils.data.DataLoader(TRAIN_DATASET, \n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   shuffle=args.train,\n",
    "                                                   num_workers=int(args.n_workers))\n",
    "TEST_DATALOADER = torch.utils.data.DataLoader(TEST_DATASET,\n",
    "                                                  batch_size=args.batch_size,\n",
    "                                                  shuffle=args.train,\n",
    "                                                  num_workers=int(args.n_workers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "received-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Network\n",
    "n_dims = 3\n",
    "net = PointNet(args.latent, n_dims, args.n_points)\n",
    "net.to(device)\n",
    "\n",
    "# Load model if there is any    \n",
    "if args.model != '':\n",
    "    net.load_state_dict(torch.load(args.model))\n",
    "\n",
    "# Set Loss function\n",
    "chamfer_distance = ChamferDistance()\n",
    "criterion = chamfer_distance\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n",
    "\n",
    "# Set Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decimal-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch=None, writer=None, epoch_str=None):    \n",
    "    # Create a Progress bar.\n",
    "    n = len(TRAIN_DATASET)\n",
    "    pbar = tqdm(total=n, leave=False)\n",
    "    \n",
    "    # Train\n",
    "    total_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(TRAIN_DATALOADER):\n",
    "        # Parse data\n",
    "        points, label, category, filename = data\n",
    "        points = points.cuda()\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Reconstruction\n",
    "        recon_ret, _ = net(points)\n",
    "        \n",
    "        # Compute Loss\n",
    "        dist1, dist2 = criterion(points, recon_ret)\n",
    "        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "        \n",
    "        # Update Parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Write results\n",
    "        if writer is not None:\n",
    "            assert(epoch is not None)\n",
    "            step = epoch * len(TRAIN_DATALOADER) + i\n",
    "            writer.add_scalar('Loss/Train', loss, step)\n",
    "            \n",
    "        batch_size = list(data[0].size())[0]\n",
    "        total_loss += loss * batch_size\n",
    "        \n",
    "        pbar.set_description('{} Train Loss: {:f}'.format(epoch_str, loss))\n",
    "        pbar.update(batch_size)\n",
    "    \n",
    "    # Close progress bar\n",
    "    pbar.close()\n",
    "    \n",
    "    mean_loss = total_loss / n\n",
    "    \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radical-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def dump_result(points, filename):\n",
    "    \"\"\"\n",
    "        points: (N, 3)\n",
    "        filename: str\n",
    "    \"\"\"\n",
    "    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n",
    "    vertex = np.array(points, dtype=[('x', 'f4'), ('y', 'f4'),('z', 'f4')])\n",
    "    el = PlyElement.describe(vertex, 'vertex', comments=['vertices'])\n",
    "    PlyData([el], text=True).write(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "other-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(epoch_str=None, dump=False):    \n",
    "    n = len(TEST_DATASET)\n",
    "    pbar = tqdm(total=n, leave=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    total_loss = 0.0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(TEST_DATALOADER):\n",
    "        # Parse data\n",
    "        points, label, category, filename = data\n",
    "        points = points.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            recon_ret, _ = net(points)\n",
    "            dist1, dist2 = criterion(points, recon_ret)\n",
    "            loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "            \n",
    "        batch_size = list(data[0].size())[0]\n",
    "        total_loss += loss * batch_size\n",
    "        \n",
    "        pbar.set_description('{} Train Loss: {:f}'.format(epoch_str, loss))\n",
    "        pbar.update(batch_size)\n",
    "        \n",
    "        if dump:\n",
    "            dump_result(points[0, :, :], './result{}/{}_points.ply'.format(args.latent, i))\n",
    "            dump_result(recon_ret[0, :, :], './result{}/{}_recon.ply'.format(args.latent, i))\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    mean_loss = total_loss / n\n",
    "    \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tested-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epoch):    \n",
    "    writer = SummaryWriter(args.out_dir)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_str = '' if epoch is None else '[Epoch {}/{}]'.format(str(epoch).zfill(len(str(args.epoch))), args.epoch)\n",
    "        \n",
    "        # Compute Loss\n",
    "        train_loss = train_one_epoch(epoch=epoch,\n",
    "                                     writer=writer,\n",
    "                                     epoch_str=epoch_str)\n",
    "        test_loss = eval_one_epoch(epoch_str=epoch_str)\n",
    "        \n",
    "        # Update Scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        if writer is not None:\n",
    "            # Write test results.\n",
    "            assert(epoch is not None)\n",
    "            step = (epoch + 1) * len(TRAIN_DATALOADER)\n",
    "            writer.add_scalar('Loss/Test', test_loss, step)\n",
    "        \n",
    "        # Log statistics\n",
    "        log = epoch_str + ' '\n",
    "        log += 'Train Loss: {:f}, '.format(train_loss)\n",
    "        log += 'Test Loss: {:f}, '.format(test_loss)\n",
    "        print(log)\n",
    "        \n",
    "        # Save the model every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model_file = os.path.join(args.out_dir, 'model{}_{:d}.pth'.format(args.latent, epoch + 1))\n",
    "            torch.save(net.state_dict(), model_file)\n",
    "            print(\"Saved '{}'.\".format(model_file))\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tribal-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    # Compute Loss\n",
    "    test_loss = eval_one_epoch(dump=True)\n",
    "    \n",
    "    # Log statistics\n",
    "    log = ''\n",
    "    log += 'Avg Chamfer Distance: {:f} for {}'.format(test_loss, args.model)\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacterial-relationship",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/35708 [00:00<?, ?it/s]{'n_points': 2048, 'latent': 512, 'train': True, 'batch_size': 32, 'epoch': 50, 'n_workers': 4, 'lr': 0.001, 'b1': 0.9, 'b2': 0.999, 'step_size': 20, 'gamma': 0.5, 'data': 'shapenetcorev2', 'model': '', 'out_dir': 'outputs'}\n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 00/50] Train Loss: 0.015170, Test Loss: 0.007377, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 01/50] Train Loss: 0.006484, Test Loss: 0.006045, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 02/50] Train Loss: 0.005455, Test Loss: 0.005078, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 03/50] Train Loss: 0.004742, Test Loss: 0.004605, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 04/50] Train Loss: 0.004340, Test Loss: 0.004251, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 05/50] Train Loss: 0.004138, Test Loss: 0.003843, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 06/50] Train Loss: 0.003936, Test Loss: 0.003777, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 07/50] Train Loss: 0.003695, Test Loss: 0.003677, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 08/50] Train Loss: 0.003641, Test Loss: 0.003913, \n",
      "[Epoch 09/50] Train Loss: 0.003467, Test Loss: 0.003432, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s]Saved 'outputs/model512_10.pth'.\n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 10/50] Train Loss: 0.003388, Test Loss: 0.003380, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 11/50] Train Loss: 0.003309, Test Loss: 0.003272, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 12/50] Train Loss: 0.003178, Test Loss: 0.003247, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 13/50] Train Loss: 0.003152, Test Loss: 0.003315, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 14/50] Train Loss: 0.003051, Test Loss: 0.003202, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 15/50] Train Loss: 0.002976, Test Loss: 0.003307, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 16/50] Train Loss: 0.002984, Test Loss: 0.003090, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 17/50] Train Loss: 0.002876, Test Loss: 0.002999, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 18/50] Train Loss: 0.002996, Test Loss: 0.003034, \n",
      "[Epoch 19/50] Train Loss: 0.002789, Test Loss: 0.002962, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s]Saved 'outputs/model512_20.pth'.\n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 20/50] Train Loss: 0.002572, Test Loss: 0.002691, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 21/50] Train Loss: 0.002502, Test Loss: 0.002712, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 22/50] Train Loss: 0.002485, Test Loss: 0.002768, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 23/50] Train Loss: 0.002437, Test Loss: 0.002681, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 24/50] Train Loss: 0.002412, Test Loss: 0.002680, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 25/50] Train Loss: 0.002416, Test Loss: 0.002697, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 26/50] Train Loss: 0.002376, Test Loss: 0.002667, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 27/50] Train Loss: 0.002359, Test Loss: 0.002732, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 28/50] Train Loss: 0.002337, Test Loss: 0.002667, \n",
      "[Epoch 29/50] Train Loss: 0.002332, Test Loss: 0.002600, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s]Saved 'outputs/model512_30.pth'.\n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 30/50] Train Loss: 0.002298, Test Loss: 0.002596, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 31/50] Train Loss: 0.002289, Test Loss: 0.002578, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 32/50] Train Loss: 0.002286, Test Loss: 0.002550, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 33/50] Train Loss: 0.002257, Test Loss: 0.002549, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 34/50] Train Loss: 0.002305, Test Loss: 0.002563, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 35/50] Train Loss: 0.002247, Test Loss: 0.002562, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 36/50] Train Loss: 0.002235, Test Loss: 0.002579, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 37/50] Train Loss: 0.002211, Test Loss: 0.002546, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 38/50] Train Loss: 0.002212, Test Loss: 0.002595, \n",
      "[Epoch 39/50] Train Loss: 0.002186, Test Loss: 0.002610, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s]Saved 'outputs/model512_40.pth'.\n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 40/50] Train Loss: 0.002100, Test Loss: 0.002433, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 41/50] Train Loss: 0.002075, Test Loss: 0.002423, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 42/50] Train Loss: 0.002060, Test Loss: 0.002420, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 43/50] Train Loss: 0.002051, Test Loss: 0.002438, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 44/50] Train Loss: 0.002053, Test Loss: 0.002423, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 45/50] Train Loss: 0.002047, Test Loss: 0.002433, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 46/50] Train Loss: 0.002032, Test Loss: 0.002449, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 47/50] Train Loss: 0.002053, Test Loss: 0.002395, \n",
      "  0%|          | 0/35708 [00:00<?, ?it/s][Epoch 48/50] Train Loss: 0.002024, Test Loss: 0.002458, \n",
      "[Epoch 49/50] Train Loss: 0.002010, Test Loss: 0.002389, \n",
      "Saved 'outputs/model512_50.pth'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(args)\n",
    "    \n",
    "    # Create the output directory.\n",
    "    if not os.path.exists(args.out_dir):\n",
    "        os.makedirs(args.out_dir)\n",
    "        \n",
    "    if args.train:\n",
    "        train(args.epoch)\n",
    "    else:\n",
    "        eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0e08e5fb7bb842dcb5f755f425ef201d971244f0250c439088a441754b3214789",
   "display_name": "Python 3.8.8 64-bit ('ae': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}